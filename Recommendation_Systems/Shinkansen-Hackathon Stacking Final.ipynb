{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d221b92",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920bd1a1",
   "metadata": {
    "id": "pvj9AGJtuTB_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d991f4",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7600708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data\n",
    "data = pd.read_csv(\"df_train_1.csv\")\n",
    "df = data.copy()\n",
    "data.shape\n",
    "\n",
    "X_train = df.drop(columns = 'Overall_Experience')\n",
    "X_train = pd.get_dummies(X_train, drop_first = True)\n",
    "X_train.shape\n",
    "\n",
    "y_train = df['Overall_Experience']\n",
    "y_train.value_counts()\n",
    "\n",
    "# Test Data\n",
    "data_test = pd.read_csv(\"df_test_1.csv\") \n",
    "df_test = data_test.copy()\n",
    "df_test.shape\n",
    "\n",
    "X_test = data_test\n",
    "X_test = pd.get_dummies(X_test, drop_first = True)\n",
    "X_test.shape\n",
    "\n",
    "y_test_ID = data_test['ID']\n",
    "\n",
    "#---------------------------------------------\n",
    "# Decision Tree\n",
    "#Defining Decision tree model with class weights class_weight={0: 0.5, 1: 0.5}\n",
    "d_tree =  DecisionTreeClassifier(random_state = 7, class_weight = {0: 0.5, 1: 0.5})\n",
    "d_tree.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = d_tree.predict(X_train)\n",
    "y_test_pred = d_tree.predict(X_test)\n",
    "\n",
    "d_tree_train_accuracy = classification_report(y_train, y_train_pred, output_dict=True)['accuracy']\n",
    "print(\"Decision Tree train accuracy:\", d_tree_train_accuracy)\n",
    "\n",
    "df_y_test_pred = pd.DataFrame({\"Overall_Experience\" : y_test_pred})\n",
    "df_y_test_ID = pd.DataFrame({\"ID\" : y_test_ID})\n",
    "res = pd.concat([ df_y_test_ID, df_y_test_pred], axis=1)\n",
    "\n",
    "res.to_csv(\"dtree.csv\", index=False)\n",
    "\n",
    "\n",
    "#---------------------------------------------\n",
    "# Random Forest\n",
    "# Defining Random forest CLassifier\n",
    "r_forest = RandomForestClassifier(random_state = 7)\n",
    "r_forest.fit(X_train,y_train)\n",
    "\n",
    "#Checking performance on the training data\n",
    "y_train_pred = r_forest.predict(X_train)\n",
    "y_test_pred = r_forest.predict(X_test)\n",
    "\n",
    "r_forest_train_accuracy = classification_report(y_train, y_train_pred, output_dict=True)['accuracy']\n",
    "print(\"Random Forest train accuracy:\", r_forest_train_accuracy)\n",
    "\n",
    "df_y_test_pred = pd.DataFrame({\"Overall_Experience\" : y_test_pred})\n",
    "df_y_test_ID = pd.DataFrame({\"ID\" : y_test_ID})\n",
    "res = pd.concat([ df_y_test_ID, df_y_test_pred], axis=1)\n",
    "res.to_csv(\"rforest.csv\", index=False)\n",
    "\n",
    "#---------------------------------------------\n",
    "# Random Forest Tuned\n",
    "# Choose the type of classifier. \n",
    "r_forest_tuned = RandomForestClassifier(criterion = \"entropy\", random_state = 1, class_weight={0: 0.5, 1: 0.5})\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "# parameters = {\n",
    "#     \"n_estimators\": [10, 110, 10],\n",
    "#     \"max_depth\": [5, 6, 7],\n",
    "#     \"max_features\": ['auto', 'sqrt', 'log2', 'None'],\n",
    "#     \"min_samples_leaf\" : np.arange(1, 15, 5),\n",
    "# #     \"min_samples_split\": np.arange(2, 20, 5),\n",
    "#              }\n",
    "\n",
    "\n",
    "parameters = {  \n",
    "#     \"max_features\" : ['sqrt', 'log2', None, .65],\n",
    "    \"max_features\": ['auto', 'sqrt', 'log2', 'None'],\n",
    "    \"min_samples_leaf\" : np.arange(1, 15, 5),\n",
    "    \"min_samples_split\": np.arange(2, 20, 5),\n",
    "    \"n_estimators\": np.arange(10, 110, 20),\n",
    "#     'n_estimators': [400], #  94.93%\n",
    "             }\n",
    "              \n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "scorer = metrics.make_scorer(accuracy_score, pos_label = 1)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(r_forest_tuned, parameters, scoring = 'f1', cv = 5, n_jobs=-1)\n",
    "\n",
    "#fit the GridSearch on train dataset\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "r_forest_tuned = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "r_forest_tuned.fit(X_train, y_train)\n",
    "y_train_pred = r_forest_tuned.predict(X_train)\n",
    "\n",
    "r_forest_tuned_train_accuracy = classification_report(y_train, y_train_pred, output_dict=True)['accuracy']\n",
    "print(\"Random Forest train accuracy:\", r_forest_tuned_train_accuracy)\n",
    "\n",
    "df_y_test_pred = pd.DataFrame({\"Overall_Experience\" : y_test_pred})\n",
    "df_y_test_ID = pd.DataFrame({\"ID\" : y_test_ID})\n",
    "res = pd.concat([ df_y_test_ID, df_y_test_pred], axis=1)\n",
    "res.to_csv(\"rforest_tuned_17.csv\", index=False)\n",
    "\n",
    "#---------------------------------------------\n",
    "# XG Boost\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "data = pd.read_csv(\"df_train_1.csv\")\n",
    "\n",
    "# Drop the dependent variable from the dataframe and create the X(independent variable) matrix\n",
    "X = data.drop(columns = 'Overall_Experience')\n",
    "X = pd.get_dummies(X, drop_first = True)\n",
    "y = data['Overall_Experience']\n",
    "\n",
    "# Remove low variance features\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selection = VarianceThreshold(threshold = (0.1))\n",
    "X = selection.fit_transform(X)\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y,  stratify = y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "X_train1.shape, X_test1.shape\n",
    "\n",
    "#Create a XGBoost Regressor\n",
    "xgboost_1 = XGBClassifier(n_estimators=10000, learning_rate=0.05,)\n",
    "xgboost_1.fit(X_train1, y_train1, early_stopping_rounds=5, eval_set=[(X_test1, y_test1)], verbose=0)\n",
    "\n",
    "# Checking performance on the testing data\n",
    "y_train_pred1 = xgboost_1.predict(X_train1)\n",
    "y_test_pred1 = xgboost_1.predict(X_test1)\n",
    "\n",
    "# test\n",
    "xgboost_1_train_accuracy = classification_report(y_train1, y_train_pred1, output_dict=True)['accuracy']\n",
    "xgboost_1_test_accuracy = classification_report(y_test1, y_test_pred1, output_dict=True)['accuracy']\n",
    "\n",
    "print(\"XGBoost train accuracy:\", xgboost_1_train_accuracy)\n",
    "print(\"XGBoost test accuracy:\", xgboost_1_test_accuracy)\n",
    "\n",
    "df_y_test_pred = pd.DataFrame({\"Overall_Experience\" : y_test_pred})\n",
    "df_y_test_ID = pd.DataFrame({\"ID\" : y_test_ID})\n",
    "res = pd.concat([ df_y_test_ID, df_y_test_pred], axis=1)\n",
    "res.to_csv(\"xgboost_2.csv\", index=False)\n",
    "\n",
    "\n",
    "#---------------------------------------------\n",
    "# SVM\n",
    "#Import svm model\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Create a svm Classifier\n",
    "svm_rbf = SVC(C=3.0, kernel='rbf', degree=3, gamma='auto') \n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = svm_rbf.predict(X_train)\n",
    "y_test_pred = svm_rbf.predict(X_test)\n",
    "\n",
    "# test\n",
    "svm_rbf_train_accuracy = classification_report(y_train, y_train_pred, output_dict=True)['accuracy']\n",
    "print(\"SVM train accuracy:\", svm_rbf_train_accuracy)\n",
    "\n",
    "df_y_test_pred = pd.DataFrame({\"Overall_Experience\" : y_test_pred})\n",
    "df_y_test_ID = pd.DataFrame({\"ID\" : y_test_ID})\n",
    "res = pd.concat([ df_y_test_ID, df_y_test_pred], axis=1)\n",
    "res.to_csv(\"svm_rbf.csv\", index=False)\n",
    "\n",
    "\n",
    "#---------------------------------------------\n",
    "# Stacking\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimators = [\n",
    "    ('d_tree', d_tree),\n",
    "    ('r_forest', r_forest),\n",
    "    ('r_forest_tuned', r_forest_tuned),   \n",
    "    ('xgboost_1', xgboost_1),\n",
    "    ('svm_rbf', svm_rbf),\n",
    "]\n",
    "\n",
    "# Build model\n",
    "stack = StackingClassifier(estimators = estimators, final_estimator = LogisticRegression ())\n",
    "\n",
    "# Train model\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# Checking performance on the testing data\n",
    "y_train_pred = stack.predict(X_train)\n",
    "y_test_pred = stack.predict(X_test)\n",
    "\n",
    "# test\n",
    "stack_train_accuracy = classification_report(y_train, y_train_pred, output_dict=True)['accuracy']\n",
    "\n",
    "print(\"Stack train accuracy:\", stack_train_accuracy)\n",
    "# merging columns and exporting\n",
    "df_y_test_pred = pd.DataFrame({\"Overall_Experience\" : y_test_pred})\n",
    "df_y_test_ID = pd.DataFrame({\"ID\" : y_test_ID})\n",
    "res = pd.concat([ df_y_test_ID, df_y_test_pred], axis=1)\n",
    "\n",
    "res.to_csv(\"stacking4.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
